import re
import datetime
from typing import List

from langchain_core.tools import tool
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_ollama import ChatOllama
from pydantic import BaseModel, Field

from pptx import Presentation
from pptx.util import Inches, Pt
from pptx.enum.text import PP_ALIGN
from pptx.dml.color import RGBColor

# --- Pydantic Schemas ---
# Defines the final data structures for the presentation.
class Slide(BaseModel):
    title: str
    subtitle: str = ""
    details: List[str] = []
    speaker_notes: str = ""

class Deck(BaseModel):
    topic: str
    slides: List[Slide]

# --- Non-LLM Helper Functions ---

def generate_outfile_name(topic: str) -> str:
    """Generates a clean, timestamped filename for the PowerPoint file."""
    sanitized_topic = re.sub(r'[^A-Za-z0-9_]+', '', topic.replace(' ', '_'))
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    return f"{sanitized_topic}_{timestamp}.pptx"

def build_pptx(deck: Deck, outfile: str) -> str:
    """Builds a .pptx file from a completed Deck object."""
    print(f"--- Building PowerPoint file: {outfile} ---")
    prs = Presentation()
    
    # Title slide
    title_slide_layout = prs.slide_layouts[0]
    slide = prs.slides.add_slide(title_slide_layout)
    slide.shapes.title.text = deck.topic
    slide.placeholders[1].text = "Generated by AI Agent"
    
    # Content slides
    for s in deck.slides:
        slide_layout = prs.slide_layouts[1] # Title and Content
        slide = prs.slides.add_slide(slide_layout)
        slide.shapes.title.text = s.title
        
        body_shape = slide.shapes.placeholders[1]
        tf = body_shape.text_frame
        tf.clear() # Clear default text
        
        # Correctly handle the first paragraph
        p = tf.paragraphs[0]
        p.text = s.details[0] if s.details else ""
        p.level = 1
        
        # Add new paragraphs for subsequent bullet points
        for detail in s.details[1:]:
            p = tf.add_paragraph()
            p.text = detail
            p.level = 1

    prs.save(outfile)
    return outfile


# --- LLM-Based Helper Functions (Text Generation) ---

def plan_deck_titles(llm: ChatOllama, topic: str, content_summary: str, slide_count: int) -> List[str]:
    """Asks the LLM for a newline-separated list of titles (plain text)."""
    print(f"\n--- Planning {slide_count} slide titles for '{topic}' ---")
    prompt = ChatPromptTemplate.from_template(
        "You are a presentation planner. Based on the topic and summary, generate a list of exactly {slide_count} slide titles. "
        "Each title should be on a new line. Do not number them or use bullet points. Respond with ONLY the list of titles."
        "\n\nTopic: {topic}\nSummary: {summary}"
    )
    chain = prompt | llm | StrOutputParser()
    result = chain.invoke({
        "topic": topic,
        "summary": content_summary,
        "slide_count": slide_count
    })
    # Parse the plain text output into a list
    return [line.strip() for line in result.strip().split('\n') if line.strip()]

def generate_single_slide_content_text(llm: ChatOllama, topic: str, content_summary: str, slide_title: str) -> str:
    """Asks the LLM for structured plain text for a single slide."""
    print(f"--- Generating content for slide: '{slide_title}' ---")
    prompt = ChatPromptTemplate.from_messages([
        ("system",
         "You are a slide content creator. Your task is to generate the content for a single slide. "
         "Use the following format, starting each section on a new line:\n"
         "Subtitle: [A brief subtitle]\n"
         "Details:\n- [Bullet point 1]\n- [Bullet point 2]\n- [Bullet point 3]\n"
         "Speaker Notes: [Optional notes for the presenter]"),
        ("user",
         "Overall Topic: {topic}\n"
         "Full Summary:\n{summary}\n\n"
         "Please generate the content for this slide title: {slide_title}")
    ])
    chain = prompt | llm | StrOutputParser()
    return chain.invoke({
        "topic": topic,
        "summary": content_summary,
        "slide_title": slide_title
    })

# --- Main Logic Function (Text Parsing) ---

def build_deck_with_llm(llm: ChatOllama, topic: str, content_summary: str, slide_count: int) -> Deck:
    """Orchestrates the text-based generation and uses a robust parser."""
    slide_titles = plan_deck_titles(llm, topic, content_summary, slide_count)
    
    generated_slides = []
    for title in slide_titles:
        try:
            raw_content = generate_single_slide_content_text(llm, topic, content_summary, title)
            
            # --- NEW ROBUST PARSER ---
            subtitle = ""
            details = []
            speaker_notes = ""
            
            current_section = None
            for line in raw_content.strip().split('\n'):
                line_lower = line.lower().strip()
                
                if line_lower.startswith("subtitle:"):
                    subtitle = line[len("subtitle:"):].strip()
                    current_section = None # Reset section after a specific header
                elif line_lower.startswith("details:"):
                    current_section = "details"
                elif line_lower.startswith("speaker notes:"):
                    current_section = "notes"
                    # Capture any notes on the same line as the header
                    speaker_notes = line[len("speaker notes:"):].strip()
                elif current_section == "details":
                    if line.strip().startswith(('-', '•', '*')):
                        details.append(line.strip().lstrip('-•* '))
                elif current_section == "notes":
                    # Append subsequent lines to the speaker notes
                    speaker_notes += " " + line.strip()

            slide = Slide(
                title=title,
                subtitle=subtitle,
                details=details,
                speaker_notes=speaker_notes.strip()
            )
            generated_slides.append(slide)
            # --- END OF NEW PARSER ---

        except Exception as e:
            print(f"   - Warning: Failed to parse content for slide '{title}'. Skipping. Error: {e}")
            generated_slides.append(Slide(title=title, details=["Content generation failed."]))
            
    return Deck(topic=topic, slides=generated_slides)


# --- The Agent's Tool ---
# This is the single function exposed to the agent.
@tool
def create_powerpoint(topic: str, summary: str, model_name: str, num_slides: int = 7) -> str:
    """
    Creates a PowerPoint presentation on a given topic using a detailed summary.
    This should be the final step after all information has been gathered.
    You MUST provide the model_name to use.
    """
    try:
        # Use a model that is good for JSON, as the helpers still use it internally for planning
        llm_planner = ChatOllama(model=model_name, temperature=0.2)
        
        planned_deck = build_deck_with_llm(llm_planner, topic, summary, num_slides)
        
        outfile = generate_outfile_name(topic)
        build_pptx(planned_deck, outfile)
        
        return f"Successfully created presentation: {outfile}"
    except Exception as e:
        return f"An unexpected error occurred while creating the PowerPoint: {e}"